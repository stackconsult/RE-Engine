{"name": "@stackconsult/reengine-llama", "version": "0.1.0", "description": "Comprehensive LLAMA integration for RE Engine with multiple model orchestration", "main": "dist/index.js", "type": "module", "scripts": {"build": "tsc -p tsconfig.json", "start": "node dist/index.js", "dev": "tsx src/index.ts", "test": "node --test"}, "keywords": ["llama", "ollama", "ai", "mcp", "re-engine", "automation", "local-ai"], "author": "StackConsult", "license": "MIT", "dependencies": {"@modelcontextprotocol/sdk": "^1.0.2", "pino": "^9.0.0", "uuid": "^10.0.0", "zod": "^3.22.4", "node-fetch": "^3.3.2"}, "devDependencies": {"@types/node": "^22.0.0", "@types/uuid": "^10.0.0", "@types/node-fetch": "^2.6.9", "tsx": "^4.7.1", "typescript": "^5.3.3"}, "files": ["dist/**/*"]}
