#!/usr/bin/env node

/**
 * Simple Ollama Validation Test
 * Tests Ollama connectivity without requiring full RE Engine build
 */

import { getOllamaService } from './engine/src/services/ollama.service.js';

async function validateOllama() {
  console.log('ü¶û Validating Ollama Integration...');
  
  try {
    // Create Ollama service
    const ollama = getOllamaService({
      baseUrl: 'http://localhost:11434',
      defaultModel: 'qwen:7b',
      timeout: 30000
    });

    console.log('‚úÖ Ollama service created');

    // Test connection
    console.log('üîó Testing connection...');
    const connected = await ollama.testConnection();
    if (!connected) {
      throw new Error('Failed to connect to Ollama');
    }
    console.log('‚úÖ Connected to Ollama successfully');

    // List models
    console.log('üìã Listing available models...');
    const models = await ollama.listModels();
    console.log(`‚úÖ Found ${models.length} models:`);
    models.forEach(model => {
      console.log(`   - ${model.name} (${model.size} bytes)`);
    });

    // Check for qwen:7b model
    const hasQwen = await ollama.hasModel('qwen:7b');
    if (!hasQwen) {
      console.warn('‚ö†Ô∏è  qwen:7b model not found, but other models are available');
    } else {
      console.log('‚úÖ qwen:7b model is available');
    }

    // Test chat completion
    console.log('üí¨ Testing chat completion...');
    const chatResponse = await ollama.chat({
      model: 'qwen:7b',
      messages: [
        { role: 'system', content: 'You are a helpful assistant.' },
        { role: 'user', content: 'Say hello in exactly 5 words.' }
      ],
      options: {
        temperature: 0.7,
        num_predict: 10
      }
    });

    if (!chatResponse.done) {
      throw new Error('Chat completion incomplete');
    }
    console.log('‚úÖ Chat completion successful');
    console.log(`   - Response: "${chatResponse.message.content}"`);
    console.log(`   - Model: ${chatResponse.model}`);
    console.log(`   - Duration: ${chatResponse.total_duration}ms`);

    // Test embeddings
    console.log('üî¢ Testing embeddings...');
    const embeddings = await ollama.embed('qwen:7b', 'test embedding');
    if (!embeddings || embeddings.length === 0) {
      throw new Error('Embeddings generation failed');
    }
    console.log(`‚úÖ Embeddings generated (${embeddings.length} dimensions)`);

    // Health check
    console.log('üè• Performing health check...');
    const health = await ollama.healthCheck();
    console.log(`‚úÖ Health status: ${health.status}`);
    console.log(`   - Connected: ${health.details.connected}`);
    console.log(`   - Models: ${health.details.modelCount}`);
    console.log(`   - Available: ${health.details.availableModels.join(', ')}`);

    console.log('');
    console.log('üéâ Ollama validation completed successfully!');
    console.log('');
    console.log('üìä Validation Results:');
    console.log('   ‚úÖ Ollama service connectivity');
    console.log('   ‚úÖ Model listing');
    console.log('   ‚úÖ Chat completions');
    console.log('   ‚úÖ Embeddings generation');
    console.log('   ‚úÖ Health monitoring');
    console.log('');
    console.log('üöÄ Ollama is ready for RE Engine integration!');

  } catch (error) {
    console.error('‚ùå Ollama validation failed:', error.message);
    console.error('');
    console.error('üîß Troubleshooting:');
    console.error('   1. Make sure Ollama is running: ollama serve');
    console.error('   2. Check Ollama models: ollama list');
    console.error('   3. Verify qwen:7b model: ollama pull qwen:7b');
    console.error('   4. Test API directly: curl http://localhost:11434/api/tags');
    console.error('   5. Check Ollama logs for errors');
    process.exit(1);
  }
}

// Run validation
validateOllama();
